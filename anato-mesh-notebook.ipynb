{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c2d210",
   "metadata": {},
   "source": [
    "# `anato-mesh` in Jupyter Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442566b4",
   "metadata": {},
   "source": [
    "`anato_mesh.py` contains the main functions for calculating the partition-level curvatures using python to reproduce the algorithm originally published by K. Khabaz here: https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011815"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200eda60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anato_mesh import *\n",
    "from anato_viz import *\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Pocivavsek lab parent directory\n",
    "parent_path = 'Z:\\\\aorta\\\\thoracic'\n",
    "#- Cohort filter\n",
    "group_str = ['KK']\n",
    "#- Mesh filter\n",
    "file_str = ['M5']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be23ef04",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"text-align:center\">quantities</th>\n",
    "        <th style=\"text-align:center\">Equation</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">'Gaussian'</td>\n",
    "        <td style=\"text-align:center\">$$\\displaystyle k_1 \\cdot k_2$$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">'Mean'</td>\n",
    "        <td style=\"text-align:center\">$$\\displaystyle 0.5 \\cdot (k_1 + k_2)$$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">'IntGaussian'</td>\n",
    "        <td style=\"text-align:center\">$$\\displaystyle (k_1 \\cdot k_2) \\cdot A$$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">'IntMeanSquared'</td>\n",
    "        <td style=\"text-align:center\">$$\\displaystyle \\left(0.5 \\cdot (k_1 + k_2)\\right)^2 \\cdot A$$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">'Willmore'</td>\n",
    "        <td style=\"text-align:center\">$$\\displaystyle 4 \\cdot \\left(0.5 \\cdot (k_1 + k_2)\\right)^2 \\cdot A - 2 \\cdot (k_1 \\cdot k_2) \\cdot A$$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">'Casorati'</td>\n",
    "        <td style=\"text-align:center\">$$\\displaystyle \\sqrt{0.5 \\cdot (k_1^2 + k_2^2)}$$</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:center\">'ShapeIndex'</td>\n",
    "        <td style=\"text-align:center\">$$\\displaystyle \\frac{2}{\\pi} \\cdot \\arctan\\left(\\frac{k_2 + k_1}{k_2 - k_1}\\right)$$</td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e067114",
   "metadata": {},
   "source": [
    "You must specify at least one variable in `quantitites` and must also define the `point_removal` method. When in doubt, use the `curvature` method because it is applicable to all geometries. The `thoracic` specific point removal process is still buggy, overly empirical, and is being fixed. If the mesh is ready to be processed as is, then set `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfcd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantities = ['Gaussian', 'Mean', 'IntGaussian', 'IntMeanSquared', 'Willmore', 'Casorati', 'ShapeIndex']\n",
    "point_removal = 'curvature'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3039d5",
   "metadata": {},
   "source": [
    "The number of surface partitions for each surface is determined by the following equation. `m_set` provides an easily adjustable parameter for further partition scaling and allows you to calculate more than one scaling at once. The optimized value for the thoracic aorta TEVAR dataset is `m=1`.\n",
    "\n",
    "$$partitions = m \\times \\left(\\frac{SA}{R^2}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54bd4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_set = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68967f4c",
   "metadata": {},
   "source": [
    "#### Executing the batch run: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e50d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results, scan_dict = GetAnatoMeshResults(parent_path, group_str, file_str, point_removal, quantities, m_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a923ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bad825b",
   "metadata": {},
   "source": [
    "### If you just want data, stop here. \n",
    "#### Everything after this are postprocessing steps including normalization, meta-data integration, visualization, and exporting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a66258",
   "metadata": {},
   "source": [
    "Normalizing the results. This works by first splitting up the compound name using the `SplitUpScanName` function and then normalizing the variables in the 2nd and 3rd function inputs to the `GroupsNormalize` function by the group of datapoints that contain the string sequence in the 4th function input. This is normally `KY` patients for TEVAR and `JX` patients for EVAR in our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_norm = GroupsNormalize(SplitUpScanName(results), 'Casorati_Mean', 'IntGaussian_Fluct', 'JX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c9123",
   "metadata": {},
   "source": [
    "Merging meta data files into the anato-mesh results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69382ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Meta data integration \n",
    "directory = 'Z:\\\\aorta\\\\meta_data'\n",
    "file_name = 'MasterMetaData.xlsx'\n",
    "\n",
    "#- Cohort meta data group names\n",
    "cohort_list = ['UC_NORMAL', 'UC_PEDS', 'UC_TEVAR', 'ENDOSPAN', 'MEDTRONIC', 'GORE_801', 'GORE_802', 'GORE_803']\n",
    "\n",
    "#- Integer columns to be converted to strings for discrete visualization\n",
    "cat_columns = ['Label', 'Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4815197",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_meta = MergeMetaData(directory, file_name, cohort_list, results_norm, cat_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfd00f1",
   "metadata": {},
   "source": [
    "Ploting and saving the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(results_norm, x='Mean_Radius', y='Total_Fluct_Norm')#, color='Label', hover_data=['Scan_Name'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveResultsToXLSX('path', 'data.xlsx', results_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456047ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveScanDictToXLSX(directory, file_name, scan_dict):\n",
    "    \"\"\"Save a dictionary as an .xlsx file.\"\"\"\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "    with pd.ExcelWriter(Path(directory) / file_name) as writer:\n",
    "        for main_key, sub_dict in scan_dict.items():\n",
    "            data = []\n",
    "            for key, values, in sub_dict.items():\n",
    "                df = pd.DataFrame(values)\n",
    "                df['key'] = key[:-3]\n",
    "                data.append(df)\n",
    "            output_df = pd.concat(data, ignore_index=True)\n",
    "            output_df.to_excel(writer, sheet_name=str(main_key), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c1fbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveScanDictToXLSX(r'Z:\\aorta\\graphs', 'KK_floating_patches.xlsx', scan_dict) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
